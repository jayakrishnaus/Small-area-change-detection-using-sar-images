{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"mount_file_id":"1pq6j4pIdE30-zqM6qAX0hmhJlEFIZNtc","authorship_tag":"ABX9TyNuptFnmrhzIneJbWWd/6UR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOgdBj0_orrV","executionInfo":{"status":"ok","timestamp":1625454553794,"user_tz":-330,"elapsed":65039,"user":{"displayName":"Jayakrishna Sukumaran.","photoUrl":"","userId":"11930586009195064231"}},"outputId":"d3858822-51ea-4ea6-d42d-dae05c62b164"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":370},"id":"FDhdPNZMmqzE","executionInfo":{"status":"error","timestamp":1625457897543,"user_tz":-330,"elapsed":2395,"user":{"displayName":"Jayakrishna Sukumaran.","photoUrl":"","userId":"11930586009195064231"}},"outputId":"3f0d135f-5d27-45c3-9042-a33cb584670f"},"source":["# example of loading a pix2pix model and using it for one-off image translation\n","from keras.models import load_model\n","from keras.preprocessing.image import img_to_array\n","from keras.preprocessing.image import load_img\n","from numpy import load\n","from numpy import expand_dims\n","from matplotlib import pyplot\n","import cv2\n","import numpy as np\n","from numpy import vstack\n","# load an image\n","def load_image(filename, size=(256,256)):\n","\t# load image with the preferred size\n","\tpixels = load_img(filename, target_size=size)\n","\t# convert to numpy array\n","\tpixels = img_to_array(pixels)\n","\t# scale from [0,255] to [-1,1]\n","\tpixels = (pixels - 127.5) / 127.5\n","\t# reshape to 1 sample\n","\tpixels = expand_dims(pixels, 0)\n","\treturn pixels\n","\n","# load source image\n","src_image = load_image('test_set\\sat.jpg')\n","gt_image = load_image('test_set\\sat_gt.jpg')\n","#cv2.imshow('Input', src_image[0])\n","#cv2.waitKey(0)\n","#cv2.destroyAllWindows()\n","print('Loaded', src_image.shape)\n","# load model\n","model = load_model('model_032880.h5')\n","# generate image from source\n","gen_image = model.predict(src_image)\n","# scale from [-1,1] to [0,1]\n","#--------------\n","\n","#cv2.imshow('dst_rt', gen_image[0])\n","#cv2.waitKey(0)\n","#cv2.destroyAllWindows()\n","\n","# plot source, generated and target images\n","\n","#-----------------\n","#pyplot.imshow(src_image[0])\n","#pyplot.show()\n","#pyplot.imshow(gt_image[0])\n","#pyplot.show()\n","#gen_image = (gen_image + 1) / 2.0\n","#pyplot.imshow(gen_image[0])\n","#pyplot.axis('off')\n","#pyplot.show()\n","\n","\n","def plot_images(src_img, gen_img, tar_img):\n","\timages = vstack((src_img, gen_img, tar_img))\n","\t# scale from [-1,1] to [0,1]\n","\timages = (images + 1) / 2.0\n","\ttitles = ['Source', 'Generated', 'Expected']\n","\t# plot images row by row\n","\tfor i in range(len(images)):\n","\t\t# define subplot\n","\t\tpyplot.subplot(1, 3, 1 + i)\n","\t\t# turn off axis\n","\t\tpyplot.axis('off')\n","\t\t# plot raw pixel data\n","\t\tpyplot.imshow(images[i])\n","\t\t# show title\n","\t\tpyplot.title(titles[i])\n","\tpyplot.show()\n","\t\n","plot_images(src_image, gen_image, gt_image)\n","\n","\n","\n","\n","\n","\n"],"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-940ef6ec8176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# load source image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0msrc_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_set\\sat.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mgt_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_set\\sat_gt.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#cv2.imshow('Input', src_image[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-940ef6ec8176>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(filename, size)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# load image with the preferred size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# convert to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    291\u001b[0m   \"\"\"\n\u001b[1;32m    292\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 293\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_set\\\\sat.jpg'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":370},"id":"Z6n88YbsoqQn","executionInfo":{"status":"error","timestamp":1625457916190,"user_tz":-330,"elapsed":1168,"user":{"displayName":"Jayakrishna Sukumaran.","photoUrl":"","userId":"11930586009195064231"}},"outputId":"35728663-4b0b-4397-ddb4-d7d0e825b297"},"source":["# example of loading a pix2pix model and using it for image to image translation\n","from keras.models import load_model\n","from numpy import load\n","from numpy import vstack\n","from matplotlib import pyplot\n","from numpy.random import randint\n","\n","# load and prepare training images\n","def load_real_samples(filename):\n","\t# load compressed arrays\n","\tdata = load(filename)\n","\t# unpack arrays\n","\tX1, X2 = data['arr_0'], data['arr_1']\n","\t# scale from [0,255] to [-1,1]\n","\tX1 = (X1 - 127.5) / 127.5\n","\tX2 = (X2 - 127.5) / 127.5\n","\treturn [X1, X2]\n","\n","# plot source, generated and target images\n","def plot_images(src_img, gen_img, tar_img):\n","\timages = vstack((src_img, gen_img, tar_img))\n","\t# scale from [-1,1] to [0,1]\n","\timages = (images + 1) / 2.0\n","\ttitles = ['Source', 'Generated', 'Expected']\n","\t# plot images row by row\n","\tfor i in range(len(images)):\n","\t\t# define subplot\n","\t\tpyplot.subplot(1, 3, 1 + i)\n","\t\t# turn off axis\n","\t\tpyplot.axis('off')\n","\t\t# plot raw pixel data\n","\t\tpyplot.imshow(images[i])\n","\t\t# show title\n","\t\tpyplot.title(titles[i])\n","\tpyplot.show()\n","\n","# load dataset\n","[X1, X2] = load_real_samples('maps_256.npz')\n","print('Loaded', X1.shape, X2.shape)\n","# load model\n","model = load_model('model_032880.h5')\n","# select random example\n","ix = randint(0, len(X1), 1)\n","src_image, tar_image = X1[ix], X2[ix]\n","# generate image from source\n","gen_image = model.predict(src_image)\n","# plot all three images\n","plot_images(src_image, gen_image, tar_image)\n"],"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-a469ca99e069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maps_256.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-a469ca99e069>\u001b[0m in \u001b[0;36mload_real_samples\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# load compressed arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# unpack arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'maps_256.npz'"]}]},{"cell_type":"code","metadata":{"id":"I4Fo5YI816Vl","executionInfo":{"status":"error","timestamp":1625457933545,"user_tz":-330,"elapsed":1894,"user":{"displayName":"Jayakrishna Sukumaran.","photoUrl":"","userId":"11930586009195064231"}},"outputId":"0b9ea8f7-6737-45a2-aa3a-61fa74559bba","colab":{"base_uri":"https://localhost:8080/","height":346}},"source":["#!/usr/bin/env python\n","# coding: utf-8\n","\n","# In[3]:\n","\n","\n","\n","# load, split and scale the maps dataset ready for training\n","from os import listdir\n","from numpy import asarray\n","from numpy import vstack\n","from keras.preprocessing.image import img_to_array\n","from keras.preprocessing.image import load_img\n","from numpy import savez_compressed\n"," \n","# load all images in a directory into memory\n","def load_images(path, size=(256,512)):\n","\tsrc_list, tar_list = list(), list()\n","\t# enumerate filenames in directory, assume all are images\n","\tfor filename in listdir(path):\n","\t\t# load and resize the image\n","\t\tpixels = load_img(path + filename, target_size=size)\n","\t\t# convert to numpy array\n","\t\tpixels = img_to_array(pixels)\n","\t\t# split into satellite and map\n","\t\tsat_img, map_img = pixels[:, :256], pixels[:, 256:]\n","\t\tsrc_list.append(sat_img)\n","\t\ttar_list.append(map_img)\n","\treturn [asarray(src_list), asarray(tar_list)]\n"," \n","# dataset path\n","#path = 'maps/train/'\n","path = 'maps/train/'\n","# load dataset\n","[src_images, tar_images] = load_images(path)\n","print('Loaded: ', src_images.shape, tar_images.shape)\n","# save as compressed numpy array\n","filename = 'maps_256.npz'\n","savez_compressed(filename, src_images, tar_images)\n","print('Saved dataset: ', filename)\n","\n","\n","# In[4]:\n","\n","\n","# load the prepared dataset\n","from numpy import load\n","from matplotlib import pyplot\n","# load the face dataset\n","data = load('maps_256.npz')\n","src_images, tar_images = data['arr_0'], data['arr_1']\n","print('Loaded: ', src_images.shape, tar_images.shape)\n","# plot source images\n","n_samples = 3\n","for i in range(n_samples):\n","\tpyplot.subplot(2, n_samples, 1 + i)\n","\tpyplot.axis('off')\n","\tpyplot.imshow(src_images[i].astype('uint8'))\n","# plot target image\n","for i in range(n_samples):\n","\tpyplot.subplot(2, n_samples, 1 + n_samples + i)\n","\tpyplot.axis('off')\n","\tpyplot.imshow(tar_images[i].astype('uint8'))\n","pyplot.show()\n","\n","\n","# In[7]:\n","\n","\n","\n","\n","\n","\n","# example of pix2pix gan for satellite to map image-to-image translation\n","from numpy import load\n","from numpy import zeros\n","from numpy import ones\n","from numpy.random import randint\n","from keras.optimizers import Adam\n","from keras.initializers import RandomNormal\n","from keras.models import Model\n","from keras.models import Input\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization\n","from keras.layers import LeakyReLU\n","from matplotlib import pyplot\n","\n","# define the discriminator model\n","def define_discriminator(image_shape):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# source image input\n","\tin_src_image = Input(shape=image_shape)\n","\t# target image input\n","\tin_target_image = Input(shape=image_shape)\n","\t# concatenate images channel-wise\n","\tmerged = Concatenate()([in_src_image, in_target_image])\n","\t# C64\n","\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# C128\n","\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","\td = BatchNormalization()(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# C256\n","\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","\td = BatchNormalization()(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# C512\n","\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","\td = BatchNormalization()(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# second last output layer\n","\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n","\td = BatchNormalization()(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# patch output\n","\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n","\tpatch_out = Activation('sigmoid')(d)\n","\t# define model\n","\tmodel = Model([in_src_image, in_target_image], patch_out)\n","\t# compile model\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n","\treturn model\n","\n","# define an encoder block\n","def define_encoder_block(layer_in, n_filters, batchnorm=True):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# add downsampling layer\n","\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n","\t# conditionally add batch normalization\n","\tif batchnorm:\n","\t\tg = BatchNormalization()(g, training=True)\n","\t# leaky relu activation\n","\tg = LeakyReLU(alpha=0.2)(g)\n","\treturn g\n","\n","# define a decoder block\n","def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# add upsampling layer\n","\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n","\t# add batch normalization\n","\tg = BatchNormalization()(g, training=True)\n","\t# conditionally add dropout\n","\tif dropout:\n","\t\tg = Dropout(0.5)(g, training=True)\n","\t# merge with skip connection\n","\tg = Concatenate()([g, skip_in])\n","\t# relu activation\n","\tg = Activation('relu')(g)\n","\treturn g\n","\n","# define the standalone generator model\n","def define_generator(image_shape=(256,256,3)):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# image input\n","\tin_image = Input(shape=image_shape)\n","\t# encoder model\n","\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n","\te2 = define_encoder_block(e1, 128)\n","\te3 = define_encoder_block(e2, 256)\n","\te4 = define_encoder_block(e3, 512)\n","\te5 = define_encoder_block(e4, 512)\n","\te6 = define_encoder_block(e5, 512)\n","\te7 = define_encoder_block(e6, 512)\n","\t# bottleneck, no batch norm and relu\n","\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n","\tb = Activation('relu')(b)\n","\t# decoder model\n","\td1 = decoder_block(b, e7, 512)\n","\td2 = decoder_block(d1, e6, 512)\n","\td3 = decoder_block(d2, e5, 512)\n","\td4 = decoder_block(d3, e4, 512, dropout=False)\n","\td5 = decoder_block(d4, e3, 256, dropout=False)\n","\td6 = decoder_block(d5, e2, 128, dropout=False)\n","\td7 = decoder_block(d6, e1, 64, dropout=False)\n","\t# output\n","\tg = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n","\tout_image = Activation('tanh')(g)\n","\t# define model\n","\tmodel = Model(in_image, out_image)\n","\treturn model\n","\n","# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model, image_shape):\n","\t# make weights in the discriminator not trainable\n","\td_model.trainable = False\n","\t# define the source image\n","\tin_src = Input(shape=image_shape)\n","\t# connect the source image to the generator input\n","\tgen_out = g_model(in_src)\n","\t# connect the source input and generator output to the discriminator input\n","\tdis_out = d_model([in_src, gen_out])\n","\t# src image as input, generated image and classification output\n","\tmodel = Model(in_src, [dis_out, gen_out])\n","\t# compile model\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n","\treturn model\n","\n","# load and prepare training images\n","def load_real_samples(filename):\n","\t# load compressed arrays\n","\tdata = load(filename)\n","\t# unpack arrays\n","\tX1, X2 = data['arr_0'], data['arr_1']\n","\t# scale from [0,255] to [-1,1]\n","\tX1 = (X1 - 127.5) / 127.5\n","\tX2 = (X2 - 127.5) / 127.5\n","\treturn [X1, X2]\n","\n","# select a batch of random samples, returns images and target\n","def generate_real_samples(dataset, n_samples, patch_shape):\n","\t# unpack dataset\n","\ttrainA, trainB = dataset\n","\t# choose random instances\n","\tix = randint(0, trainA.shape[0], n_samples)\n","\t# retrieve selected images\n","\tX1, X2 = trainA[ix], trainB[ix]\n","\t# generate 'real' class labels (1)\n","\ty = ones((n_samples, patch_shape, patch_shape, 1))\n","\treturn [X1, X2], y\n","\n","# generate a batch of images, returns images and targets\n","def generate_fake_samples(g_model, samples, patch_shape):\n","\t# generate fake instance\n","\tX = g_model.predict(samples)\n","\t# create 'fake' class labels (0)\n","\ty = zeros((len(X), patch_shape, patch_shape, 1))\n","\treturn X, y\n","\n","# generate samples and save as a plot and save the model\n","def summarize_performance(step, g_model, dataset, n_samples=3):\n","\t# select a sample of input images\n","\t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n","\t# generate a batch of fake samples\n","\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n","\t# scale all pixels from [-1,1] to [0,1]\n","\tX_realA = (X_realA + 1) / 2.0\n","\tX_realB = (X_realB + 1) / 2.0\n","\tX_fakeB = (X_fakeB + 1) / 2.0\n","\t# plot real source images\n","\tfor i in range(n_samples):\n","\t\tpyplot.subplot(3, n_samples, 1 + i)\n","\t\tpyplot.axis('off')\n","\t\tpyplot.imshow(X_realA[i])\n","\t# plot generated target image\n","\tfor i in range(n_samples):\n","\t\tpyplot.subplot(3, n_samples, 1 + n_samples + i)\n","\t\tpyplot.axis('off')\n","\t\tpyplot.imshow(X_fakeB[i])\n","\t# plot real target image\n","\tfor i in range(n_samples):\n","\t\tpyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n","\t\tpyplot.axis('off')\n","\t\tpyplot.imshow(X_realB[i])\n","\t# save plot to file\n","\tfilename1 = 'plot_%06d.png' % (step+1)\n","\tpyplot.savefig(filename1)\n","\tpyplot.close()\n","\t# save the generator model\n","\tfilename2 = 'model_%06d.h5' % (step+1)\n","\tg_model.save(filename2)\n","\tprint('>Saved: %s and %s' % (filename1, filename2))\n","\n","# train pix2pix models\n","def train(d_model, g_model, gan_model, dataset, n_epochs=80, n_batch=1):\n","\t# determine the output square shape of the discriminator\n","\tn_patch = d_model.output_shape[1]\n","\t# unpack dataset\n","\ttrainA, trainB = dataset\n","\t# calculate the number of batches per training epoch\n","\tbat_per_epo = int(len(trainA) / n_batch)\n","\t# calculate the number of training iterations\n","\tn_steps = bat_per_epo * n_epochs\n","\t# manually enumerate epochs\n","\tfor i in range(n_steps):\n","\t\t# select a batch of real samples\n","\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n","\t\t# generate a batch of fake samples\n","\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n","\t\t# update discriminator for real samples\n","\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n","\t\t# update discriminator for generated samples\n","\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n","\t\t# update the generator\n","\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n","\t\t# summarize performance\n","\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n","\t\t# summarize model performance\n","\t\tif (i+1) % (bat_per_epo * 10) == 0:\n","\t\t\tsummarize_performance(i, g_model, dataset)\n","\n","# load image data\n","dataset = load_real_samples('maps_256.npz')\n","print('Loaded', dataset[0].shape, dataset[1].shape)\n","# define input shape based on the loaded dataset\n","image_shape = dataset[0].shape[1:]\n","# define the models\n","d_model = define_discriminator(image_shape)\n","g_model = define_generator(image_shape)\n","# define the composite model\n","gan_model = define_gan(g_model, d_model, image_shape)\n","# train model\n","train(d_model, g_model, gan_model, dataset)\n","\n"],"execution_count":6,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-29cb545d2c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'maps/train/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0msrc_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_images\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# save as compressed numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-29cb545d2c0b>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(path, size)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msrc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# enumerate filenames in directory, assume all are images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# load and resize the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'maps/train/'"]}]},{"cell_type":"code","metadata":{"id":"Q7jsnUQF17A9"},"source":[""],"execution_count":null,"outputs":[]}]}